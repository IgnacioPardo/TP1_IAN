{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 914.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia del ambiente\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from agente import AgenteQLearning\n",
    "from ambiente import AmbienteDiezMil\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "ambiente = AmbienteDiezMil()\n",
    "\n",
    "# Crear un agente de Q-learning\n",
    "agente = AgenteQLearning(ambiente)\n",
    "episodios = 10000\n",
    "\n",
    "# Entrenar al agente con un número de episodios\n",
    "agente.entrenar(episodios, verbose=True)\n",
    "# agente.guardar_politica(f\"politica_{episodios}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 600 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m val \u001b[38;5;241m=\u001b[39m Validador(ambiente)\n\u001b[1;32m      6\u001b[0m val_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 7\u001b[0m avg \u001b[38;5;241m=\u001b[39m \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidar_politica\u001b[49m\u001b[43m(\u001b[49m\u001b[43magente\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_table2pol\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidación DeepPurple: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m val_rand \u001b[38;5;241m=\u001b[39m Validador(ambiente)\n",
      "File \u001b[0;32m~/Desktop/code/TP1_IAN/template.py:50\u001b[0m, in \u001b[0;36mValidador.validar_politica\u001b[0;34m(self, politica, episodios)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Dada una política entrenada, se valida su desempeño en el ambiente.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    float: Turnos promedio necesarios para llegar a 10.000.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m jugador \u001b[38;5;241m=\u001b[39m JugadorFromPolicy(politica)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidar_jugador\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjugador\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/TP1_IAN/template.py:34\u001b[0m, in \u001b[0;36mValidador.validar_jugador\u001b[0;34m(self, jugador, episodios)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodios):\n\u001b[1;32m     33\u001b[0m     juego \u001b[38;5;241m=\u001b[39m JuegoDiezMil(jugador)\n\u001b[0;32m---> 34\u001b[0m     cantidad_turnos, _ \u001b[38;5;241m=\u001b[39m \u001b[43mjuego\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjugar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     turnos\u001b[38;5;241m.\u001b[39mappend(cantidad_turnos)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(turnos)\n",
      "File \u001b[0;32m~/Desktop/code/TP1_IAN/diezmil.py:41\u001b[0m, in \u001b[0;36mJuegoDiezMil.jugar\u001b[0;34m(self, verbose, tope_turnos)\u001b[0m\n\u001b[1;32m     37\u001b[0m     puntaje_turno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Bien, suma puntos. Preguntamos al jugador qué quiere hacer.\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     jugada, dados_a_tirar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjugador\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjugar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpuntaje_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpuntaje_turno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdados\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jugada \u001b[38;5;241m==\u001b[39m JUGADA_PLANTARSE:\n\u001b[1;32m     46\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/code/TP1_IAN/jugador.py:131\u001b[0m, in \u001b[0;36mJugadorFromPolicy.jugar\u001b[0;34m(self, puntaje_total, puntaje_turno, dados, verbose)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m puntaje \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m     pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m jugada \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposibles_acciones[\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolitica\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mno_usados\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    132\u001b[0m ]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jugada \u001b[38;5;241m==\u001b[39m JUGADA_PLANTARSE:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (JUGADA_PLANTARSE, [])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 600 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "from jugador import JugadorAleatorio, JugadorFromPolicyV2, JugadorSiempreSePlanta\n",
    "from template import Validador\n",
    "np.random.seed(seed)\n",
    "\n",
    "val = Validador(ambiente)\n",
    "val_count = 10000\n",
    "# avg = val.validar_politica(agente.q_table2pol(), val_count)\n",
    "jugador = JugadorFromPolicyV2(\"DeepPurple\", agente.q_table2pol())\n",
    "avg = val.validar_jugador(jugador, val_count)\n",
    "print(f\"Validación DeepPurple: {avg}\")\n",
    "\n",
    "val_rand = Validador(ambiente)\n",
    "jugador = JugadorAleatorio(\"random\")\n",
    "avg_rand = val_rand.validar_jugador(jugador, val_count)\n",
    "print(f\"Validación Random: {avg_rand}\")\n",
    "\n",
    "val_planton = Validador(ambiente)\n",
    "jugador = JugadorSiempreSePlanta(\"plantón\")\n",
    "avg_planton = val_planton.validar_jugador(jugador, val_count)\n",
    "print(f\"Validación Plantón: {avg_planton}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': np.float64(0.4), 'gamma': np.float64(0.2), 'epsilon': np.float64(0.05), 'reward_func': np.int64(5)}, avg: 23.18: 100%|██████████| 100/100 [01:02<00:00,  1.61it/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': np.float64(0.4), 'gamma': np.float64(0.2), 'epsilon': np.float64(0.05), 'reward_func': np.int64(5)}, avg: 23.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "# alpha: float = 0.1,\n",
    "# gamma: float = 0.9,\n",
    "# epsilon: float = 0.1,\n",
    "\n",
    "paramter_space = {\n",
    "    \"alpha\": np.arange(0.1, 1.1, 0.1),\n",
    "    \"gamma\": np.arange(0.0, 1.2, 0.2),\n",
    "    \"epsilon\": np.arange(0.05, 0.25, 0.05),\n",
    "    \"reward_func\": list(range(0, 9))\n",
    "}\n",
    "val_count = 50\n",
    "\n",
    "best_avg = 35\n",
    "best_params = None\n",
    "\n",
    "# Random search\n",
    "from tqdm import tqdm\n",
    "iter = tqdm(range(100))\n",
    "for i in iter:\n",
    "    alpha = np.random.choice(paramter_space[\"alpha\"])\n",
    "    gamma = np.random.choice(paramter_space[\"gamma\"])\n",
    "    epsilon = np.random.choice(paramter_space[\"epsilon\"])\n",
    "    reward_func = np.random.choice(paramter_space[\"reward_func\"])\n",
    "\n",
    "    ambiente = AmbienteDiezMil(reward_func_type=reward_func)\n",
    "    agente = AgenteQLearning(ambiente, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    vals = list(agente.entrenar(episodios))\n",
    "    avg = val.validar_politica(agente.q_table2pol(), val_count)\n",
    "\n",
    "    if best_avg > avg:\n",
    "        best_avg = avg\n",
    "        best_params = {\n",
    "            \"alpha\": alpha,\n",
    "            \"gamma\": gamma,\n",
    "            \"epsilon\": epsilon,\n",
    "            \"reward_func\": reward_func\n",
    "        }\n",
    "        iter.set_description(f\"Best params: {best_params}, avg: {best_avg}\")\n",
    "\n",
    "print(f\"Best params: {best_params}, avg: {best_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57236/100000 [00:42<00:31, 1338.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m episodios \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Entrenar al agente con un número de episodios\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magente\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentrenar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m val \u001b[38;5;241m=\u001b[39m Validador(ambiente)\n\u001b[1;32m     11\u001b[0m val_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/code/TP1_IAN/template.py:370\u001b[0m, in \u001b[0;36mentrenar\u001b[0;34m(self, episodios, verbose, validate)\u001b[0m\n\u001b[1;32m    367\u001b[0m     val \u001b[38;5;241m=\u001b[39m Validador(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mambiente)\n\u001b[1;32m    368\u001b[0m     val_promedio \u001b[38;5;241m=\u001b[39m val\u001b[38;5;241m.\u001b[39mvalidar_politica(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table2pol(), \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisodio \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Validación: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_promedio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m val_promedio\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/std.py:1394\u001b[0m, in \u001b[0;36mtqdm.set_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;241m=\u001b[39m desc \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[0;32m-> 1394\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[1;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 459\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/std.py:453\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m    452\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[0;32m--> 453\u001b[0m     \u001b[43mfp_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/tqdm/utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/ipykernel/iostream.py:607\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m evt \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n\u001b[0;32m--> 607\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/ipykernel/iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     f()\n",
      "File \u001b[0;32m~/Desktop/code/ia_neuro/.conda/lib/python3.10/site-packages/zmq/sugar/socket.py:701\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    695\u001b[0m             data,\n\u001b[1;32m    696\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    697\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    698\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    699\u001b[0m         )\n\u001b[1;32m    700\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_zmq.py:1092\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:1140\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:1339\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:160\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ambiente = AmbienteDiezMil(reward_func_type=best_params[\"reward_func\"])\n",
    "\n",
    "# Crear un agente de Q-learning\n",
    "agente = AgenteQLearning(ambiente)\n",
    "episodios = 100000\n",
    "\n",
    "# Entrenar al agente con un número de episodios\n",
    "list(agente.entrenar(episodios, verbose=True))\n",
    "\n",
    "val = Validador(ambiente)\n",
    "val_count = 1000\n",
    "avg = val.validar_politica(agente.q_table2pol(), val_count)\n",
    "print(f\"Validación DeepPurple: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 47.32trial/s, best loss: 23.02]\n",
      "{'alpha': np.float64(0.7948009830124299), 'epsilon': np.float64(0.07536342092227688), 'gamma': np.float64(0.9998031968152667)}\n"
     ]
    }
   ],
   "source": [
    "# HyperOpt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def objective(params):\n",
    "    alpha = params[\"alpha\"]\n",
    "    gamma = params[\"gamma\"]\n",
    "    epsilon = params[\"epsilon\"]\n",
    "\n",
    "    ambiente = AmbienteDiezMil(reward_func_type=7)\n",
    "\n",
    "    agente = AgenteQLearning(ambiente, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    agente.entrenar(episodios)\n",
    "    avg = val.validar_politica(agente.q_table2pol(), val_count)\n",
    "\n",
    "    return {\n",
    "        \"loss\": avg,\n",
    "        \"status\": STATUS_OK,\n",
    "    }\n",
    "\n",
    "space = {\n",
    "    \"alpha\": hp.uniform(\"alpha\", 0.1, 1.0),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0.0, 1.0),\n",
    "    \"epsilon\": hp.uniform(\"epsilon\", 0.05, 0.25),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials, verbose=1)\n",
    "print(best)\n",
    "\n",
    "# Entrenar al agente con un número de episodios\n",
    "agente = AgenteQLearning(ambiente, **best)\n",
    "vals = list(agente.entrenar(episodios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
